{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T16:32:50.431848Z",
     "start_time": "2024-01-18T16:32:50.423357Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T16:32:50.930711Z",
     "start_time": "2024-01-18T16:32:50.432388Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from evaluation import evaluate_heursitic_grid\n",
    "from policies.heuristics import TCBMHeuristicAgent\n",
    "from environments.road_env import RoadEnvironment\n",
    "from environments.config.environment_presets import smallest_environment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T16:34:11.595247Z",
     "start_time": "2024-01-18T16:32:50.930969Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/420 [00:00<?, ?it/s]Process SpawnPoolWorker-24:\n",
      "Process SpawnPoolWorker-21:\n",
      "  0%|          | 1/420 [01:19<9:11:52, 79.03s/it]Process SpawnPoolWorker-9:\n",
      "Process SpawnPoolWorker-7:\n",
      "Process SpawnPoolWorker-6:\n",
      "Process SpawnPoolWorker-18:\n",
      "Process SpawnPoolWorker-1:\n",
      "Process SpawnPoolWorker-2:\n",
      "Process SpawnPoolWorker-8:\n",
      "Process SpawnPoolWorker-11:\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 135, in step\n",
      "    self.observation = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 369, in step\n",
      "    observation = self._get_observation()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 281, in _get_observation\n",
      "    adjacency_matrix = np.array(self.graph.get_adjacency().data)\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 124, in step\n",
      "    next_deterioration_state = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 186, in update_edge_travel_time_factors\n",
      "    self.base_time_factor = np.sum(btt_vec)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 358, in step\n",
      "    for i, edge in enumerate(self.graph.es):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 124, in step\n",
      "    next_deterioration_state = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 141, in step\n",
      "    self.belief = self.deterioration_table[action].T @ self.belief\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 183, in update_edge_travel_time_factors\n",
      "    btt_vec, cap_vec = np.hsplit(\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 938, in hsplit\n",
      "    return split(ary, indices_or_sections, 1)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 866, in split\n",
      "    return array_split(ary, indices_or_sections, axis)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 782, in array_split\n",
      "    sub_arys.append(_nx.swapaxes(sary[st:end], axis, 0))\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 581, in swapaxes\n",
      "    return _wrapfunc(a, 'swapaxes', axis1, axis2)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 54, in _wrapfunc\n",
      "    bound = getattr(obj, method, None)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 135, in step\n",
      "    self.observation = self.random_generator.choice(\n",
      "  File \"numpy/random/_generator.pyx\", line 811, in numpy.random._generator.Generator.choice\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 416, in issubdtype\n",
      "    if not issubclass_(arg1, generic):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 319, in issubclass_\n",
      "    try:\n",
      "KeyboardInterrupt\n",
      "\n",
      "Process SpawnPoolWorker-4:\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 361, in step\n",
      "    total_travel_time = self._get_total_travel_time()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 318, in _get_total_travel_time\n",
      "    path = self.graph.get_shortest_paths(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 361, in step\n",
      "    total_travel_time = self._get_total_travel_time()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 318, in _get_total_travel_time\n",
      "    path = self.graph.get_shortest_paths(\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-15:\n",
      "Process SpawnPoolWorker-23:\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 132, in step\n",
      "    reward = self.state_action_reward[self.state][action]\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 764, in array_split\n",
      "    Nsections = len(indices_or_sections) + 1\n",
      "TypeError: object of type 'int' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 183, in update_edge_travel_time_factors\n",
      "    btt_vec, cap_vec = np.hsplit(\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 938, in hsplit\n",
      "    return split(ary, indices_or_sections, 1)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 866, in split\n",
      "    return array_split(ary, indices_or_sections, axis)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 773, in array_split\n",
      "    extras * [Neach_section+1] +\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 124, in step\n",
      "    next_deterioration_state = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 149, in step\n",
      "    self.belief /= np.sum(self.belief)  # normalize\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-19:\n",
      "Process SpawnPoolWorker-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 764, in array_split\n",
      "    Nsections = len(indices_or_sections) + 1\n",
      "TypeError: object of type 'int' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 183, in update_edge_travel_time_factors\n",
      "    btt_vec, cap_vec = np.hsplit(\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 938, in hsplit\n",
      "    return split(ary, indices_or_sections, 1)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 866, in split\n",
      "    return array_split(ary, indices_or_sections, axis)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/lib/shape_base.py\", line 775, in array_split\n",
      "    div_points = _nx.array(section_sizes, dtype=_nx.intp).cumsum()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 135, in step\n",
      "    self.observation = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 141, in step\n",
      "    self.belief = self.deterioration_table[action].T @ self.belief\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-27:\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 369, in step\n",
      "    observation = self._get_observation()\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-5:\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 124, in step\n",
      "    next_deterioration_state = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 129, in step\n",
      "    self.base_travel_time = self.base_travel_time_table[action][self.state]\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 287, in _get_observation\n",
      "    edge_beliefs.append(edge[\"road_segments\"].get_beliefs())\n",
      "Process SpawnPoolWorker-29:\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 223, in get_beliefs\n",
      "    return [segment.belief for segment in self.segments]\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 187, in update_edge_travel_time_factors\n",
      "    self.capacity_factor = np.sum(\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 72, in _wrapreduction\n",
      "    passkwargs = {k: v for k, v in kwargs.items()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 187, in update_edge_travel_time_factors\n",
      "    self.capacity_factor = np.sum(\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-32:\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 149, in step\n",
      "    self.belief /= np.sum(self.belief)  # normalize\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-10:\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 135, in step\n",
      "    self.observation = self.random_generator.choice(\n",
      "  File \"numpy/random/_generator.pyx\", line 811, in numpy.random._generator.Generator.choice\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 357, in issubdtype\n",
      "    @set_module('numpy')\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 141, in step\n",
      "    self.belief = self.deterioration_table[action].T @ self.belief\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 135, in step\n",
      "    self.observation = self.random_generator.choice(\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-22:\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 320, in issubclass_\n",
      "    return issubclass(arg1, arg2)\n",
      "TypeError: issubclass() arg 1 must be a class\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 204, in step\n",
      "    segment_reward = segment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 124, in step\n",
      "    next_deterioration_state = self.random_generator.choice(\n",
      "  File \"numpy/random/_generator.pyx\", line 811, in numpy.random._generator.Generator.choice\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 416, in issubdtype\n",
      "    if not issubclass_(arg1, generic):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/numerictypes.py\", line 320, in issubclass_\n",
      "    return issubclass(arg1, arg2)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 369, in step\n",
      "    observation = self._get_observation()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 281, in _get_observation\n",
      "    adjacency_matrix = np.array(self.graph.get_adjacency().data)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/igraph/adjacency.py\", line 62, in _get_adjacency\n",
      "    return Matrix(GraphBase.get_adjacency(self, type))\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/igraph/datatypes.py\", line 26, in __init__\n",
      "    self.data = data\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/igraph/datatypes.py\", line 73, in _set_data\n",
      "    def _set_data(self, data=None):\n",
      "KeyboardInterrupt\n",
      "Process SpawnPoolWorker-26:\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 188, in update_edge_travel_time_factors\n",
      "    self.calculate_bpr_capacity_factor(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 179, in calculate_bpr_capacity_factor\n",
      "    return base_time_vec * self.bpr_alpha / (capacity_vec**self.bpr_beta)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 53, in evaluate_heuristic\n",
      "    reward_mean, reward_std = evaluate_agent(\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 44, in evaluate_agent\n",
      "    reward, _ = collect_episode(agent, environment)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/policies/evaluation.py\", line 19, in collect_episode\n",
      "    next_observation, reward, done, info = environment.step(action)\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 359, in step\n",
      "    maintenance_reward += edge[\"road_segments\"].step(actions[i])\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 210, in step\n",
      "    self.update_edge_travel_time_factors()\n",
      "  File \"/Users/pascalleroy/Documents/imp-rl-challenge/environments/road_env.py\", line 186, in update_edge_travel_time_factors\n",
      "    self.base_time_factor = np.sum(btt_vec)\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 2313, in sum\n",
      "    return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n",
      "  File \"/Users/pascalleroy/micromamba/envs/compet3.9/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 88, in _wrapreduction\n",
      "    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m number_of_episodes \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10000\u001B[39m\n\u001B[1;32m     12\u001B[0m filename \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresults/TCBM_heuristic_grid_search_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mthreshold_area\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m0.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00minspection_interval_area\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnumber_of_episodes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 14\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_heursitic_grid\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43menvironment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheuristic_class\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mTCBMHeuristicAgent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparameter_dict\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mparameter_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumber_of_episodes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnumber_of_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnumber_of_processes\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresult_path\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mfilename\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverwrite\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m results\n",
      "File \u001B[0;32m~/Documents/imp-rl-challenge/policies/evaluation.py:100\u001B[0m, in \u001B[0;36mevaluate_heursitic_grid\u001B[0;34m(heuristic_class, environment, parameter_dict, number_of_episodes, number_of_processes, result_path, overwrite)\u001B[0m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m job \u001B[38;5;129;01min\u001B[39;00m jobs:\n\u001B[1;32m     99\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m--> 100\u001B[0m     reward_mean, reward_std, parameters \u001B[38;5;241m=\u001B[39m \u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    101\u001B[0m     results\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;28mlen\u001B[39m(results)] \u001B[38;5;241m=\u001B[39m [parameters[k] \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m parameter_keys] \u001B[38;5;241m+\u001B[39m [\n\u001B[1;32m    102\u001B[0m         reward_mean,\n\u001B[1;32m    103\u001B[0m         reward_std,\n\u001B[1;32m    104\u001B[0m         number_of_episodes,\n\u001B[1;32m    105\u001B[0m     ]\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result_path \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    766\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    767\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m~/micromamba/envs/compet3.9/lib/python3.9/multiprocessing/pool.py:762\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    761\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 762\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/micromamba/envs/compet3.9/lib/python3.9/threading.py:581\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    579\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    580\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 581\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m~/micromamba/envs/compet3.9/lib/python3.9/threading.py:312\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    311\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 312\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    313\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    314\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "parameter_dict = {\n",
    "    \"threshold\": np.arange(0,1.05,0.05),\n",
    "    \"inspection_interval\": np.arange(1, 21),\n",
    "}\n",
    "\n",
    "environment = RoadEnvironment(**smallest_environment_dict)\n",
    "\n",
    "threshold_area = 0.5\n",
    "inspection_interval_area = 10\n",
    "\n",
    "number_of_episodes = 10000\n",
    "filename = f\"results/TCBM_heuristic_grid_search_{threshold_area:0.2f}_{inspection_interval_area}_{number_of_episodes}\"\n",
    "\n",
    "results = evaluate_heursitic_grid(\n",
    "    environment = environment,\n",
    "    heuristic_class = TCBMHeuristicAgent,\n",
    "    parameter_dict = parameter_dict,\n",
    "    number_of_episodes = number_of_episodes,\n",
    "    number_of_processes = 32,\n",
    "    result_path = f\"{filename}.csv\",\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T16:34:11.570703Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "# load results\n",
    "filename = \"results/TCBM_heuristic_grid_search_0.13_10_10000\"\n",
    "results = pd.read_csv(f\"{filename}.csv\")\n",
    "\n",
    "# find best parameters\n",
    "best = results.sort_values(\"reward_mean\", ascending=False).head(1)\n",
    "best_reward_mean = best[\"reward_mean\"].values[0]\n",
    "best_reward_std = best[\"reward_std\"].values[0]\n",
    "best_reward_std_error = best[\"reward_std\"].values[0] / np.sqrt(best[\"episodes\"].values[0])\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best)\n",
    "print(\"\\t with std error: {:.2f}\".format(best_reward_std_error))\n",
    "\n",
    "std_error_reward_range = best_reward_mean - best_reward_std_error\n",
    "\n",
    "best_results = results[results[\"reward_mean\"] >= std_error_reward_range].sort_values(\"reward_mean\", ascending=False)\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T16:34:11.573318Z"
    }
   },
   "outputs": [],
   "source": [
    "# load results\n",
    "results = pd.read_csv(f\"{filename}.csv\")\n",
    "\n",
    "# plot results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=results, x=\"threshold\", y=\"reward_mean\", hue=\"inspection_interval\", ax=ax, palette=\"tab10\" # options: \"Set1\", \"Set2\", \"Set3\", \"tab10\", \"Paired\"\n",
    ")\n",
    "ax.set_title(\"TCBM Heuristic Grid Search\")\n",
    "ax.set_ylabel(\"Mean Reward\")\n",
    "\n",
    "plt.savefig(f\"{filename}.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-18T16:34:11.576567Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot as 2d heatmap\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "results[\"threshold\"] = results[\"threshold\"].round(5)\n",
    "results[\"inspection_interval\"] = results[\"inspection_interval\"].astype(int)\n",
    "\n",
    "results = results.pivot(index=\"threshold\", columns=\"inspection_interval\", values=\"reward_mean\")\n",
    "\n",
    "# make reward_mean positive\n",
    "results = -results\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(results, ax=ax, norm=LogNorm())\n",
    "ax.set_title(\"TCBM Heuristic Grid Search (Log Scale)\")\n",
    "ax.set_ylabel(\"Threshold\")\n",
    "ax.set_xlabel(\"Inspection Interval\")\n",
    "ax.collections[0].colorbar.set_label(\"Average Cost\")\n",
    "\n",
    "plt.savefig(f\"{filename}_heatmap.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
