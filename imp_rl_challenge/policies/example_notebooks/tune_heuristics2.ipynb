{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "from evaluation import evaluate_heursitic_grid\n",
    "from policies.heuristics import TCBMHeuristicAgent\n",
    "from environments.road_env import RoadEnvironment\n",
    "from environments.config.environment_presets import smallest_environment_dict\n",
    "parameter_dict = {\n",
    "    \"threshold\": np.arange(0,1.05,0.05),\n",
    "    \"inspection_interval\": np.arange(1, 21),\n",
    "}\n",
    "\n",
    "environment = RoadEnvironment(**smallest_environment_dict)\n",
    "\n",
    "threshold_area = 0.5\n",
    "inspection_interval_area = 10\n",
    "\n",
    "number_of_episodes = 10000\n",
    "filename = f\"results/TCBM_heuristic_grid_search_{threshold_area:0.2f}_{inspection_interval_area}_{number_of_episodes}\"\n",
    "\n",
    "results = evaluate_heursitic_grid(\n",
    "    environment = environment,\n",
    "    heuristic_class = TCBMHeuristicAgent,\n",
    "    parameter_dict = parameter_dict,\n",
    "    number_of_episodes = number_of_episodes,\n",
    "    number_of_processes = 32,\n",
    "    result_path = f\"{filename}.csv\",\n",
    "    overwrite = True,\n",
    ")\n",
    "\n",
    "results\n",
    "import pandas as pd \n",
    "# load results\n",
    "filename = \"results/TCBM_heuristic_grid_search_0.13_10_10000\"\n",
    "results = pd.read_csv(f\"{filename}.csv\")\n",
    "\n",
    "# find best parameters\n",
    "best = results.sort_values(\"reward_mean\", ascending=False).head(1)\n",
    "best_reward_mean = best[\"reward_mean\"].values[0]\n",
    "best_reward_std = best[\"reward_std\"].values[0]\n",
    "best_reward_std_error = best[\"reward_std\"].values[0] / np.sqrt(best[\"episodes\"].values[0])\n",
    "\n",
    "print(\"Best parameters:\")\n",
    "print(best)\n",
    "print(\"\\t with std error: {:.2f}\".format(best_reward_std_error))\n",
    "\n",
    "std_error_reward_range = best_reward_mean - best_reward_std_error\n",
    "\n",
    "best_results = results[results[\"reward_mean\"] >= std_error_reward_range].sort_values(\"reward_mean\", ascending=False)\n",
    "best_results\n",
    "# load results\n",
    "results = pd.read_csv(f\"{filename}.csv\")\n",
    "\n",
    "# plot results\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.lineplot(\n",
    "    data=results, x=\"threshold\", y=\"reward_mean\", hue=\"inspection_interval\", ax=ax, palette=\"tab10\" # options: \"Set1\", \"Set2\", \"Set3\", \"tab10\", \"Paired\"\n",
    ")\n",
    "ax.set_title(\"TCBM Heuristic Grid Search\")\n",
    "ax.set_ylabel(\"Mean Reward\")\n",
    "\n",
    "plt.savefig(f\"{filename}.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# plot as 2d heatmap\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "results[\"threshold\"] = results[\"threshold\"].round(5)\n",
    "results[\"inspection_interval\"] = results[\"inspection_interval\"].astype(int)\n",
    "\n",
    "results = results.pivot(index=\"threshold\", columns=\"inspection_interval\", values=\"reward_mean\")\n",
    "\n",
    "# make reward_mean positive\n",
    "results = -results\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.heatmap(results, ax=ax, norm=LogNorm())\n",
    "ax.set_title(\"TCBM Heuristic Grid Search (Log Scale)\")\n",
    "ax.set_ylabel(\"Threshold\")\n",
    "ax.set_xlabel(\"Inspection Interval\")\n",
    "ax.collections[0].colorbar.set_label(\"Average Cost\")\n",
    "\n",
    "plt.savefig(f\"{filename}_heatmap.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
